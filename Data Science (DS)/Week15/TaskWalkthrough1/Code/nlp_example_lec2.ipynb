{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nlp\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default spaCy NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x000002A6017126F0>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x000002A601712090>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x000002A6017173E0>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x000002A6019B6A10>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x000002A601A167D0>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x000002A6017174C0>)]\n"
     ]
    }
   ],
   "source": [
    "#Create the nlp object\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "print(nlp.pipe_names)\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a custom component in the NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: ['custom_component', 'tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# Define a custom component\n",
    "# Make a function execute automatically when you call nlp\n",
    "\n",
    "@Language.component(\"custom_component\")\n",
    "def custom_component_function(doc):\n",
    "    # Print the doc's length\n",
    "    print(\"Doc length:\", len(doc))\n",
    "    # Return the doc object\n",
    "    return doc\n",
    "\n",
    "# Add the component first in the pipeline\n",
    "nlp.add_pipe(\"custom_component\", first=True)\n",
    "\n",
    "# Print the pipeline component names\n",
    "print(\"Pipeline:\", nlp.pipe_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customising the poistion of the custom component in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # last: If True, add last\n",
    "# nlp.add_pipe(\"custom_component\", last=True)\n",
    "\n",
    "# # first: If True, add first\n",
    "# nlp.add_pipe(\"custom_component\", first=True)\n",
    "\n",
    "# # before: Add before componenet\n",
    "# nlp.add_pipe(\"custom_component\", before=\"ner\")\n",
    "\n",
    "# # after: Add after componenet\n",
    "# nlp.add_pipe(\"custom_component\", after=\"tagger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using spaCy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between the sentences: 0.8570134262541451\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "# To use word vectors, install larger models ending in md or lg\n",
    "# en_core_web_md or en_core_web_lg\n",
    "\n",
    "# Run the next line only the first time to download\n",
    "#! python -m spacy download en_core_web_md\n",
    "\n",
    "# Load spaCy model with pre-trained word embeddings\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Process the sentence to obtain Doc objects\n",
    "doc1 = nlp(\"I like cats and dogs\")\n",
    "doc2 = nlp(\"I love all animals\")\n",
    "\n",
    "# Access the vector representations of the entire sentences\n",
    "embeddings1, embeddings2 = doc1.vector, doc2.vector\n",
    "\n",
    "# Calculate the similarity between the embeddings\n",
    "similarity = doc1.similarity(doc2)\n",
    "\n",
    "# Print the similarity\n",
    "print(\"Similarity between the sentences:\",similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity between sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy similarity\n",
      "Query: The collapse of tourism and its impact on wildlife\n",
      "Nearest neighbors: 2\n",
      "Poaching and illegal wildlife trafficking trends in Southern Africa - Distance: 0.2246145\n",
      "The tourism industry is collapsing - Distance: 0.3102746\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    \"The tourism industry is collapsing\",\n",
    "    \"The COVID-19 travel shock hit  tourism-dependent economies hard\",\n",
    "    \"Poaching and illegal wildlife trafficking trends in Southern Africa\",\n",
    "]\n",
    "\n",
    "# Query\n",
    "query = \"The collapse of tourism and its impact on wildlife\"\n",
    "\n",
    "# Compute sentence embeddings\n",
    "sentence_embeddings = [nlp(sentence).vector for sentence in sentences]\n",
    "\n",
    "# Convert sentence embeddings to numpy array\n",
    "sentence_embeddings = np.array(sentence_embeddings)\n",
    "\n",
    "# Create NearestNeighbors model\n",
    "k = 2  # Number of nearest neighbors to find\n",
    "nn_model = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "nn_model.fit(sentence_embeddings)\n",
    "\n",
    "# Query for nearest neighbors\n",
    "query_embedding = nlp(query).vector.reshape(1, -1)  # Reshape for compatibility with sklearn\n",
    "distances, indices = nn_model.kneighbors(query_embedding)\n",
    "\n",
    "# Print nearest neighbors\n",
    "print('spaCy similarity')\n",
    "print(\"Query:\", query)\n",
    "print(\"Nearest neighbors:\",k)\n",
    "for i, index in enumerate(indices[0]):\n",
    "    print(sentences[index], \"- Distance:\", distances[0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baking' 'batter' 'chips' 'chocolate' 'cocoa' 'combine' 'dish' 'dry'\n",
      " 'flour' 'lightly' 'mix' 'oven' 'pour' 'powder' 'preheat' 'spray'\n",
      " 'sprinkle' 'sugar' 'the']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baking</th>\n",
       "      <th>batter</th>\n",
       "      <th>chips</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>cocoa</th>\n",
       "      <th>combine</th>\n",
       "      <th>dish</th>\n",
       "      <th>dry</th>\n",
       "      <th>flour</th>\n",
       "      <th>lightly</th>\n",
       "      <th>mix</th>\n",
       "      <th>oven</th>\n",
       "      <th>pour</th>\n",
       "      <th>powder</th>\n",
       "      <th>preheat</th>\n",
       "      <th>spray</th>\n",
       "      <th>sprinkle</th>\n",
       "      <th>sugar</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   baking  batter  chips  chocolate  cocoa  combine  dish  dry  flour  \\\n",
       "0       0       0      0          0      0        0     0    0      0   \n",
       "1       1       0      0          0      0        0     1    0      0   \n",
       "2       0       0      1          1      1        1     0    0      1   \n",
       "3       0       0      0          0      0        0     0    1      0   \n",
       "4       0       1      0          0      0        0     0    0      0   \n",
       "\n",
       "   lightly  mix  oven  pour  powder  preheat  spray  sprinkle  sugar  the  \n",
       "0        0    0     1     0       0        1      0         0      0    1  \n",
       "1        1    0     0     0       0        0      1         0      0    1  \n",
       "2        0    0     0     0       1        0      0         0      1    1  \n",
       "3        0    1     0     0       0        0      0         1      0    1  \n",
       "4        0    0     0     1       0        0      0         0      0    1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use steps of a recipe as phrases\n",
    "corpus = [\n",
    "   'Preheat the oven',\n",
    "   'lightly spray the baking dish', \n",
    "   'combine the sugar, flour, cocoa powder, chocolate chips',\n",
    "   'Sprinkle the dry mix',\n",
    "   'Pour the batter',\n",
    "]\n",
    "\n",
    "# import and instantiate the vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# apply the vectorizer to the corpus\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# display the document-term matrix as a \n",
    "# pandas dataframe to show the tokens\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "docterm = pd.DataFrame(X.todense(), columns=vocab)\n",
    "print(vocab)\n",
    "docterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW similarity\n",
      "Query: The collapse of tourism and its impact on wildlife\n",
      "Nearest neighbors: 2\n",
      "The tourism industry is collapsing - Distance: 0.5527864045000421\n",
      "Poaching and illegal wildlife trafficking trends in Southern Africa - Distance: 0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    \"The tourism industry is collapsing\",\n",
    "    \"The COVID-19 travel shock hit  tourism-dependent economies hard\",\n",
    "    \"Poaching and illegal wildlife trafficking trends in Southern Africa\",\n",
    "]\n",
    "\n",
    "# Query\n",
    "query = \"The collapse of tourism and its impact on wildlife\"\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the sentences to obtain count vectors\n",
    "sentence_vectors = vectorizer.fit_transform(sentences)\n",
    "\n",
    "# Transform the query to obtain its count vector\n",
    "query_vector = vectorizer.transform([query])\n",
    "\n",
    "# Create NearestNeighbors model\n",
    "k = 2  # Number of nearest neighbors to find\n",
    "nn_model = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "nn_model.fit(sentence_vectors)\n",
    "\n",
    "# Query for nearest neighbors\n",
    "distances, indices = nn_model.kneighbors(query_vector)\n",
    "\n",
    "# Print nearest neighbors\n",
    "print('BoW similarity')\n",
    "print(\"Query:\", query)\n",
    "print(\"Nearest neighbors:\",k)\n",
    "for i, index in enumerate(indices[0]):\n",
    "    print(sentences[index], \"- Distance:\", distances[0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample documents\n",
    "new_corpus = [\n",
    "   \"The quick brown fox jumps over the lazy dog\",\n",
    "   \"The dog barks at the fox\",\n",
    "   \"The fox is quick and the dog is lazy\"\n",
    "]\n",
    "\n",
    "# import and instantiate the BoW vectorizer\n",
    "bow_vectorizer = CountVectorizer()\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Learn the vocabulary and transform the documents into a BoW and TF-IDF matrix\n",
    "bow_matrix = bow_vectorizer.fit_transform(new_corpus)\n",
    "tfidf_matrix = vectorizer.fit_transform(new_corpus)\n",
    "\n",
    "# Get the vocabulary (unique words) and their corresponding indices\n",
    "bow_vocabulary = bow_vectorizer.get_feature_names_out()\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# display the document-term matrix as a \n",
    "# pandas dataframe to show the tokens\n",
    "bow_docterm = pd.DataFrame(bow_matrix.todense(), columns=bow_vocabulary)\n",
    "docterm = pd.DataFrame(tfidf_matrix.todense(), columns=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>at</th>\n",
       "      <th>barks</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>is</th>\n",
       "      <th>jumps</th>\n",
       "      <th>lazy</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  at  barks  brown  dog  fox  is  jumps  lazy  over  quick  the\n",
       "0    0   0      0      1    1    1   0      1     1     1      1    2\n",
       "1    0   1      1      0    1    1   0      0     0     0      0    2\n",
       "2    1   0      0      0    1    1   2      0     1     0      1    2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_docterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>at</th>\n",
       "      <th>barks</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>is</th>\n",
       "      <th>jumps</th>\n",
       "      <th>lazy</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400008</td>\n",
       "      <td>0.236251</td>\n",
       "      <td>0.236251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400008</td>\n",
       "      <td>0.304216</td>\n",
       "      <td>0.400008</td>\n",
       "      <td>0.304216</td>\n",
       "      <td>0.472502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.494289</td>\n",
       "      <td>0.494289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291935</td>\n",
       "      <td>0.291935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.34816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205629</td>\n",
       "      <td>0.205629</td>\n",
       "      <td>0.696321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264785</td>\n",
       "      <td>0.411258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       and        at     barks     brown       dog       fox        is  \\\n",
       "0  0.00000  0.000000  0.000000  0.400008  0.236251  0.236251  0.000000   \n",
       "1  0.00000  0.494289  0.494289  0.000000  0.291935  0.291935  0.000000   \n",
       "2  0.34816  0.000000  0.000000  0.000000  0.205629  0.205629  0.696321   \n",
       "\n",
       "      jumps      lazy      over     quick       the  \n",
       "0  0.400008  0.304216  0.400008  0.304216  0.472502  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.583870  \n",
       "2  0.000000  0.264785  0.000000  0.264785  0.411258  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docterm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
